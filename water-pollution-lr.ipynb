{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hydramst/water-pollution-linreg?scriptVersionId=132380010\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import GridSearchCV\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-13T15:26:15.21669Z","iopub.execute_input":"2022-06-13T15:26:15.217112Z","iopub.status.idle":"2022-06-13T15:26:15.232831Z","shell.execute_reply.started":"2022-06-13T15:26:15.217078Z","shell.execute_reply":"2022-06-13T15:26:15.231723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_train = pd.read_csv('/kaggle/input/water-pollution/water_pollution_dataset/Train.csv', delimiter = ',')\nDF_test = pd.read_csv('/kaggle/input/water-pollution/water_pollution_dataset/Test.csv', delimiter = ',')\nTarget = pd.read_csv('/kaggle/input/water-pollution/water_pollution_dataset/Target.csv', delimiter = ',')\nSubmission = pd.read_csv('/kaggle/input/water-pollution/water_pollution_dataset/Submission.csv', delimiter = ',')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:15.47627Z","iopub.execute_input":"2022-06-13T15:26:15.47673Z","iopub.status.idle":"2022-06-13T15:26:15.503853Z","shell.execute_reply.started":"2022-06-13T15:26:15.476698Z","shell.execute_reply":"2022-06-13T15:26:15.50269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Target","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:15.634589Z","iopub.execute_input":"2022-06-13T15:26:15.634996Z","iopub.status.idle":"2022-06-13T15:26:15.648653Z","shell.execute_reply.started":"2022-06-13T15:26:15.634963Z","shell.execute_reply":"2022-06-13T15:26:15.647563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check if ID's in train presented in train","metadata":{}},{"cell_type":"code","source":"print('intersection of train and test ID\\'s:', \n      len(set(DF_train['id'].values).intersection(set(DF_test['id'].values)))/len(set(DF_test['id'].values)))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:15.718793Z","iopub.execute_input":"2022-06-13T15:26:15.720068Z","iopub.status.idle":"2022-06-13T15:26:15.728927Z","shell.execute_reply.started":"2022-06-13T15:26:15.72Z","shell.execute_reply":"2022-06-13T15:26:15.727653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"63% of test ID's presented in train","metadata":{}},{"cell_type":"code","source":"ids_intest = pd.DataFrame(DF_test['id'].values)\nids_intrain = pd.DataFrame(set(DF_train['id'].values).intersection(set(DF_test['id'].values)))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:15.798968Z","iopub.execute_input":"2022-06-13T15:26:15.799392Z","iopub.status.idle":"2022-06-13T15:26:15.806514Z","shell.execute_reply.started":"2022-06-13T15:26:15.799361Z","shell.execute_reply":"2022-06-13T15:26:15.80561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"in_train = []\nnotin_train = []\n\nfor value in ids_intest.values:\n    if (value in ids_intrain.values):\n        in_train +=[value]\n    else:\n        notin_train +=[value]\n        \nid_notin_train = pd.DataFrame(notin_train, columns=['id'])\nid_in_train = pd.DataFrame(in_train, columns=['id'])\n\nprint('ID presented in train:',len(in_train))\n\nprint( 'ID not presented in train:', len(notin_train))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:15.88121Z","iopub.execute_input":"2022-06-13T15:26:15.882447Z","iopub.status.idle":"2022-06-13T15:26:15.895902Z","shell.execute_reply.started":"2022-06-13T15:26:15.882393Z","shell.execute_reply":"2022-06-13T15:26:15.894517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Concatinate train and test","metadata":{}},{"cell_type":"code","source":"df = pd.concat([DF_train, DF_test])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:16.000947Z","iopub.execute_input":"2022-06-13T15:26:16.001343Z","iopub.status.idle":"2022-06-13T15:26:16.011187Z","shell.execute_reply.started":"2022-06-13T15:26:16.00131Z","shell.execute_reply":"2022-06-13T15:26:16.010267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns = ['Unnamed: 0'])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:16.157714Z","iopub.execute_input":"2022-06-13T15:26:16.158421Z","iopub.status.idle":"2022-06-13T15:26:16.166162Z","shell.execute_reply.started":"2022-06-13T15:26:16.158368Z","shell.execute_reply":"2022-06-13T15:26:16.165085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## View categorical and numerical columns","metadata":{}},{"cell_type":"code","source":"cat_columns = []\nnum_columns = []\n\nfor column_name in df.columns:\n    if (df[column_name].dtypes == object):\n        cat_columns +=[column_name]\n    else:\n        num_columns +=[column_name]\n\nprint('categorical columns:\\t ',cat_columns, '\\n len = ',len(cat_columns))\n\nprint('numerical columns:\\t ',  num_columns, '\\n len = ',len(num_columns))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:16.272187Z","iopub.execute_input":"2022-06-13T15:26:16.27265Z","iopub.status.idle":"2022-06-13T15:26:16.280748Z","shell.execute_reply.started":"2022-06-13T15:26:16.272617Z","shell.execute_reply":"2022-06-13T15:26:16.279894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Move 'year' to num columns ","metadata":{}},{"cell_type":"code","source":"cat_columns = ['code', 'period', 'id', 'Country', 'year']\nnum_columns = [ 'tourists', 'venue', 'rate', 'food', 'glass', 'metal', 'other', 'paper', 'plastic', 'leather', 'green_waste', 'waste_recycling'] ","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:16.386875Z","iopub.execute_input":"2022-06-13T15:26:16.387548Z","iopub.status.idle":"2022-06-13T15:26:16.394147Z","shell.execute_reply.started":"2022-06-13T15:26:16.387483Z","shell.execute_reply":"2022-06-13T15:26:16.3929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fill NaN values with mean and ffill (for object) values","metadata":{}},{"cell_type":"code","source":"df_new = pd.concat([df, id_notin_train])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:16.530841Z","iopub.execute_input":"2022-06-13T15:26:16.53125Z","iopub.status.idle":"2022-06-13T15:26:16.541616Z","shell.execute_reply.started":"2022-06-13T15:26:16.531218Z","shell.execute_reply":"2022-06-13T15:26:16.540381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new[num_columns].fillna(df[num_columns].mean())\ndf_new = df.ffill()\ndf_new.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:16.648357Z","iopub.execute_input":"2022-06-13T15:26:16.64878Z","iopub.status.idle":"2022-06-13T15:26:16.674829Z","shell.execute_reply.started":"2022-06-13T15:26:16.648747Z","shell.execute_reply":"2022-06-13T15:26:16.673665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fill missing Target values with mean","metadata":{}},{"cell_type":"code","source":"mean_targ = Target['polution'].mean()\ntarg = []\nfor i in range(0, len(id_notin_train)):\n    targ += [mean_targ]\n    \n#Target = pd.concat([Target, pd.DataFrame(targ, columns=['polution'])])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:16.717558Z","iopub.execute_input":"2022-06-13T15:26:16.718449Z","iopub.status.idle":"2022-06-13T15:26:16.725847Z","shell.execute_reply.started":"2022-06-13T15:26:16.71841Z","shell.execute_reply":"2022-06-13T15:26:16.724402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## OHE ","metadata":{}},{"cell_type":"code","source":"df_ohe = pd.get_dummies(df[cat_columns])\ndf_all = pd.concat([df_ohe, df[num_columns]], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:16.825911Z","iopub.execute_input":"2022-06-13T15:26:16.826406Z","iopub.status.idle":"2022-06-13T15:26:16.86801Z","shell.execute_reply.started":"2022-06-13T15:26:16.826371Z","shell.execute_reply":"2022-06-13T15:26:16.866799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scaling","metadata":{}},{"cell_type":"code","source":"# Creating StandardScaler Object\nscaler = StandardScaler()\ndf_scale = pd.DataFrame(scaler.fit_transform(df_all[num_columns]))\ndf_all = pd.concat([df_ohe.reset_index(drop=True), df_scale.reset_index(drop=True)], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:16.975771Z","iopub.execute_input":"2022-06-13T15:26:16.976824Z","iopub.status.idle":"2022-06-13T15:26:16.998695Z","shell.execute_reply.started":"2022-06-13T15:26:16.976752Z","shell.execute_reply":"2022-06-13T15:26:16.997564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split back to test and train \n","metadata":{}},{"cell_type":"code","source":"len_test = len(DF_test)\ntrain = df_all.iloc[:-len_test]\ntest = df_all.iloc[-len_test:]\nprint(DF_train.shape[0], train.shape[0], DF_test.shape[0], test.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:17.132405Z","iopub.execute_input":"2022-06-13T15:26:17.132818Z","iopub.status.idle":"2022-06-13T15:26:17.14023Z","shell.execute_reply.started":"2022-06-13T15:26:17.132785Z","shell.execute_reply":"2022-06-13T15:26:17.138785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Log Scaling of Target","metadata":{}},{"cell_type":"code","source":"target_log = np.log(Target['polution'])\ntarget_orig = Target['polution']","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:17.295445Z","iopub.execute_input":"2022-06-13T15:26:17.296731Z","iopub.status.idle":"2022-06-13T15:26:17.302163Z","shell.execute_reply.started":"2022-06-13T15:26:17.296671Z","shell.execute_reply":"2022-06-13T15:26:17.301364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Traintest split","metadata":{}},{"cell_type":"code","source":"X, y = pd.DataFrame(train).values, target_orig.values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train.shape[0], X_test.shape[0], y_train.shape[0], y_test.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:17.444471Z","iopub.execute_input":"2022-06-13T15:26:17.445613Z","iopub.status.idle":"2022-06-13T15:26:17.503102Z","shell.execute_reply.started":"2022-06-13T15:26:17.445507Z","shell.execute_reply":"2022-06-13T15:26:17.501987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:17.556942Z","iopub.execute_input":"2022-06-13T15:26:17.55796Z","iopub.status.idle":"2022-06-13T15:26:17.565233Z","shell.execute_reply.started":"2022-06-13T15:26:17.557918Z","shell.execute_reply":"2022-06-13T15:26:17.564079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GridSearchCV","metadata":{}},{"cell_type":"code","source":"### define model\nmodel = Ridge()\n\nalphas = np.array([1,0.1,0.01,0.001,0.0001,0.000001, 0.0000001])\n\n# define parameters\nparam = {\n    'alpha':alphas,\n    'positive':[True, False],\n    'copy_X':[True,False],\n    'fit_intercept':[True,False]\n    \n}\n#grid = GridSearchCV(model, param, scoring='r2', cv=2, n_jobs=-1)\n#grid.fit(X_train, y_train)\n#predictions = grid.predict(X_test)\n#print('R2 : %.4f' %  r2_score(y_test,predictions))\n#print('R2 : %.4f' % grid.best_score_)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:17.645962Z","iopub.execute_input":"2022-06-13T15:26:17.646375Z","iopub.status.idle":"2022-06-13T15:26:17.652891Z","shell.execute_reply.started":"2022-06-13T15:26:17.646342Z","shell.execute_reply":"2022-06-13T15:26:17.651954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ElasticNetCV","metadata":{}},{"cell_type":"code","source":"model_ElasticCV = ElasticNetCV(n_alphas=1, fit_intercept=True, max_iter=100000, l1_ratio=0.9, eps=0.0001, cv=5)\n\n#model_ElasticCV.fit(X_train, y_train)\n\n#y_predict_ElasticCV = model_ElasticCV.predict(X_test)\n\n#print('R2 : %.4f' %  r2_score(y_test,y_predict_ElasticCV))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:17.71305Z","iopub.execute_input":"2022-06-13T15:26:17.713866Z","iopub.status.idle":"2022-06-13T15:26:17.71989Z","shell.execute_reply.started":"2022-06-13T15:26:17.713816Z","shell.execute_reply":"2022-06-13T15:26:17.718857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ElasticNet","metadata":{}},{"cell_type":"code","source":"model_Elastic = ElasticNet(alpha=0.005, fit_intercept=True, max_iter=100000, l1_ratio=0.1)\n\nmodel_Elastic.fit(X_train, y_train)\n\ny_predict_Elastic = model_Elastic.predict(X_test)\n\nprint('R2 : %.4f' %  r2_score(y_test,y_predict_Elastic))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:17.804079Z","iopub.execute_input":"2022-06-13T15:26:17.804831Z","iopub.status.idle":"2022-06-13T15:26:18.185133Z","shell.execute_reply.started":"2022-06-13T15:26:17.804792Z","shell.execute_reply":"2022-06-13T15:26:18.183921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ridge LR","metadata":{}},{"cell_type":"code","source":"model = Ridge(alpha = 0.1, fit_intercept=True, max_iter=10000)\n\nmodel.fit(X_train, y_train)\n\ny_predict=model.predict(X_test)\n\nprint('Error on test data:')\nprint('MSE: %.1f' % mse(y_test,y_predict))\nprint('RMSE: %.1f' % mse(y_test,y_predict,squared=False))\nprint('R2 : %.4f' %  r2_score(y_test,y_predict))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:18.191811Z","iopub.execute_input":"2022-06-13T15:26:18.192735Z","iopub.status.idle":"2022-06-13T15:26:18.578579Z","shell.execute_reply.started":"2022-06-13T15:26:18.192674Z","shell.execute_reply":"2022-06-13T15:26:18.577318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lasso","metadata":{}},{"cell_type":"code","source":"model_L = Lasso(alpha=0.00001, fit_intercept=True)\n\nmodel_L.fit(X_train, y_train)\ny_predict=model_L.predict(X_test)\n\nprint('R2 : %.4f' %  r2_score(y_test,y_predict))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:18.580111Z","iopub.execute_input":"2022-06-13T15:26:18.58059Z","iopub.status.idle":"2022-06-13T15:26:22.829548Z","shell.execute_reply.started":"2022-06-13T15:26:18.580543Z","shell.execute_reply":"2022-06-13T15:26:22.828364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compare answers with original values","metadata":{}},{"cell_type":"code","source":"def plotGraph(y_test,y_predict,regressorName):\n    if max(y_test) >= max(y_predict):\n        my_range = int(max(y_test))\n    else:\n        my_range = int(max(y_predict))\n    plt.scatter(range(len(y_test)), y_test, color='blue')\n    plt.scatter(range(len(y_predict)), y_predict, color='red')\n    plt.title(regressorName)\n    plt.show()\n    return\n\n\nplotGraph(y_test, y_predict_Elastic, \"Elastic: RED - predicted. BLUE - original\")\nplotGraph(y_test, y_predict, \"Ridge: RED - predicted. BLUE - original\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:22.835805Z","iopub.execute_input":"2022-06-13T15:26:22.83692Z","iopub.status.idle":"2022-06-13T15:26:23.567085Z","shell.execute_reply.started":"2022-06-13T15:26:22.836871Z","shell.execute_reply":"2022-06-13T15:26:23.565855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross validation","metadata":{}},{"cell_type":"code","source":"def cross_val(model, X_train, y_train):\n  scoring = {'R2': 'r2',\n            '-MSE': 'neg_mean_squared_error',\n            '-MAE': 'neg_mean_absolute_error',\n            'Max': 'max_error'}\n\n\n  scores = cross_validate(model, X_train, y_train,\n                        scoring=scoring, cv=ShuffleSplit(n_splits=5, random_state=42) )\n\n  print('CV Results')\n  DF_cv_linreg = pd.DataFrame(scores)\n  display(DF_cv_linreg)\n  print('\\n')\n  print(DF_cv_linreg.mean()[2:])\n  print('\\n')\n\ncross_val(model, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:23.568967Z","iopub.execute_input":"2022-06-13T15:26:23.569317Z","iopub.status.idle":"2022-06-13T15:26:25.299863Z","shell.execute_reply.started":"2022-06-13T15:26:23.569287Z","shell.execute_reply":"2022-06-13T15:26:25.298676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tests","metadata":{}},{"cell_type":"markdown","source":"### Export model","metadata":{}},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:25.306214Z","iopub.execute_input":"2022-06-13T15:26:25.309567Z","iopub.status.idle":"2022-06-13T15:26:25.321296Z","shell.execute_reply.started":"2022-06-13T15:26:25.309478Z","shell.execute_reply":"2022-06-13T15:26:25.318952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('model.pkl', 'wb') as f:\n    pickle.dump(model, f)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:31:59.371756Z","iopub.execute_input":"2022-06-13T15:31:59.372245Z","iopub.status.idle":"2022-06-13T15:31:59.379234Z","shell.execute_reply.started":"2022-06-13T15:31:59.372206Z","shell.execute_reply":"2022-06-13T15:31:59.377839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! ls","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:25.354156Z","iopub.execute_input":"2022-06-13T15:26:25.354931Z","iopub.status.idle":"2022-06-13T15:26:26.127851Z","shell.execute_reply.started":"2022-06-13T15:26:25.354871Z","shell.execute_reply":"2022-06-13T15:26:26.126472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pytest","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:26.132103Z","iopub.execute_input":"2022-06-13T15:26:26.132921Z","iopub.status.idle":"2022-06-13T15:26:26.139648Z","shell.execute_reply.started":"2022-06-13T15:26:26.13286Z","shell.execute_reply":"2022-06-13T15:26:26.138578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! rm /kaggle/working/water-pollution/Tests\n! mkdir /kaggle/working/water-pollution/Tests\n! touch /kaggle/working/water-pollution/Tests.py","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:26.141282Z","iopub.execute_input":"2022-06-13T15:26:26.14186Z","iopub.status.idle":"2022-06-13T15:26:28.417342Z","shell.execute_reply.started":"2022-06-13T15:26:26.141811Z","shell.execute_reply":"2022-06-13T15:26:28.416088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile /kaggle/working/water-pollution/Tests.py\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import GridSearchCV\nimport pickle\n\n\ndef test_data_preprocessing():\n    DF_train = pd.read_csv('/kaggle/input/water-pollution/water_pollution_dataset/Train.csv', delimiter = ',')\n    DF_test = pd.read_csv('/kaggle/input/water-pollution/water_pollution_dataset/Test.csv', delimiter = ',')\n    Target = pd.read_csv('/kaggle/input/water-pollution/water_pollution_dataset/Target.csv', delimiter = ',')\n    Submission = pd.read_csv('/kaggle/input/water-pollution/water_pollution_dataset/Submission.csv', delimiter = ',')\n    \n    \n    df = pd.concat([DF_train, DF_test])\n    \n    cat_columns = ['code', 'period', 'id', 'Country', 'year']\n    num_columns = [ 'tourists', 'venue', 'rate', 'food', 'glass', 'metal', 'other', 'paper', 'plastic', 'leather', 'green_waste', 'waste_recycling'] \n    \n    df_ohe = pd.get_dummies(df[cat_columns])\n    df_all = pd.concat([df_ohe, df[num_columns]], axis=1)\n    \n    # Creating StandardScaler Object\n    scaler = StandardScaler()\n    df_scale = pd.DataFrame(scaler.fit_transform(df_all[num_columns]))\n    df_all = pd.concat([df_ohe.reset_index(drop=True), df_scale.reset_index(drop=True)], axis=1)\n    \n    len_test = len(DF_test)\n    train = df_all.iloc[:-len_test]\n    test = df_all.iloc[-len_test:]\n    target_orig = Target['polution']\n    \n    X, y = pd.DataFrame(train).values, target_orig.values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    with open('model.pkl', 'rb') as f:\n        loaded_model = pickle.load(f)\n    y_predict = loaded_model.predict(X_test)\n    assert r2_score(y_test,y_predict) < 0.9\n \n\ndef test_model_2():\n    DF_train = pd.read_csv('/kaggle/input/water-pollution/water_pollution_dataset/Train.csv', delimiter = ',')\n    DF_test = pd.read_csv('/kaggle/input/water-pollution/water_pollution_dataset/Test.csv', delimiter = ',')\n    Target = pd.read_csv('/kaggle/input/water-pollution/water_pollution_dataset/Target.csv', delimiter = ',')\n    Submission = pd.read_csv('/kaggle/input/water-pollution/water_pollution_dataset/Submission.csv', delimiter = ',')\n    \n    \n    df = pd.concat([DF_train, DF_test])\n    \n    cat_columns = ['code', 'period', 'id', 'Country', 'year']\n    num_columns = [ 'tourists', 'venue', 'rate', 'food', 'glass', 'metal', 'other', 'paper', 'plastic', 'leather', 'green_waste', 'waste_recycling'] \n   \n    df_ohe = pd.get_dummies(df[cat_columns])\n    df_all = pd.concat([df_ohe, df[num_columns]], axis=1)\n    \n    # Creating StandardScaler Object\n    scaler = StandardScaler()\n    df_scale = pd.DataFrame(scaler.fit_transform(df_all[num_columns]))\n    df_all = pd.concat([df_ohe.reset_index(drop=True), df_scale.reset_index(drop=True)], axis=1)\n    \n    len_test = len(DF_test)\n    train = df_all.iloc[:-len_test]\n    test = df_all.iloc[-len_test:]\n    target_orig = Target['polution']\n    \n    X, y = pd.DataFrame(train).values, target_orig.values\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=42)\n    \n    with open('model.pkl', 'rb') as f:\n        loaded_model = pickle.load(f)\n    y_predict = loaded_model.predict(X_test)\n    assert r2_score(y_test,y_predict) < 0.4 ","metadata":{"execution":{"iopub.status.busy":"2022-06-13T16:02:34.94939Z","iopub.execute_input":"2022-06-13T16:02:34.950448Z","iopub.status.idle":"2022-06-13T16:02:34.961942Z","shell.execute_reply.started":"2022-06-13T16:02:34.95039Z","shell.execute_reply":"2022-06-13T16:02:34.96094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! cat /kaggle/working/water-pollution/Tests.py ","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:28.435406Z","iopub.execute_input":"2022-06-13T15:26:28.436303Z","iopub.status.idle":"2022-06-13T15:26:29.211687Z","shell.execute_reply.started":"2022-06-13T15:26:28.436258Z","shell.execute_reply":"2022-06-13T15:26:29.210169Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pytest /kaggle/working/water-pollution/Tests.py","metadata":{"execution":{"iopub.status.busy":"2022-06-13T16:02:37.538843Z","iopub.execute_input":"2022-06-13T16:02:37.539519Z","iopub.status.idle":"2022-06-13T16:02:40.759599Z","shell.execute_reply.started":"2022-06-13T16:02:37.539452Z","shell.execute_reply":"2022-06-13T16:02:40.758503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predict = model.predict(test)\n\n# Convert back from log scaling\n#y_predict = np.exp(y_predict)\n\nSubmission['polution'] = y_predict\nSubmission","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:33.675738Z","iopub.execute_input":"2022-06-13T15:26:33.676178Z","iopub.status.idle":"2022-06-13T15:26:33.724689Z","shell.execute_reply.started":"2022-06-13T15:26:33.676139Z","shell.execute_reply":"2022-06-13T15:26:33.723684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! rm /kaggle/working/water-pollution/Submission.csv\n! mkdir /kaggle/working/water-pollution/\nSubmission['polution'][27] = 2.0","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:33.726417Z","iopub.execute_input":"2022-06-13T15:26:33.727397Z","iopub.status.idle":"2022-06-13T15:26:35.315343Z","shell.execute_reply.started":"2022-06-13T15:26:33.727334Z","shell.execute_reply":"2022-06-13T15:26:35.313975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Submission.to_csv('/kaggle/working/water-pollution/Submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:26:35.317365Z","iopub.execute_input":"2022-06-13T15:26:35.317771Z","iopub.status.idle":"2022-06-13T15:26:35.326041Z","shell.execute_reply.started":"2022-06-13T15:26:35.317733Z","shell.execute_reply":"2022-06-13T15:26:35.325073Z"},"trusted":true},"execution_count":null,"outputs":[]}]}