{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\nimport xgboost as xg\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom catboost import CatBoostClassifier, Pool\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_train = pd.read_csv('/kaggle/input/water-pollution/water pollution (data for classification models)/Train.csv', delimiter = ',')\nDF_test = pd.read_csv('/kaggle/input/water-pollution/water pollution (data for classification models)/Test.csv', delimiter = ',')\nTarget = pd.read_csv('/kaggle/input/water-pollution/water pollution (data for classification models)/Target.csv', delimiter = ',')\nSubmission = pd.read_csv('/kaggle/input/water-pollution/water pollution (data for classification models)/Submission.csv', delimiter = ',')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Target.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Concatinate train and test","metadata":{}},{"cell_type":"code","source":"df = pd.concat([DF_train, DF_test])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## View categorical and numerical columns\n","metadata":{}},{"cell_type":"code","source":"cat_columns = []\nnum_columns = []\n\nfor column_name in df.columns:\n    if (df[column_name].dtypes == object):\n        cat_columns +=[column_name]\n    else:\n        num_columns +=[column_name]\n\nprint('categorical columns:\\t ',cat_columns, '\\n len = ',len(cat_columns))\n\nprint('numerical columns:\\t ',  num_columns, '\\n len = ',len(num_columns))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Move 'year' to num columns\n","metadata":{}},{"cell_type":"code","source":"cat_columns = ['code', 'period', 'id', 'Country', 'year']\nnum_columns = ['Unnamed: 0', 'tourists', 'venue', 'rate', 'food', 'glass', 'metal', 'other', 'paper', 'plastic', 'leather', 'green_waste', 'waste_recycling'] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OHE","metadata":{}},{"cell_type":"code","source":"df_ohe = pd.get_dummies(df[cat_columns])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all = pd.concat([df_ohe, df[num_columns]], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train test split","metadata":{}},{"cell_type":"code","source":"# Creating StandardScaler Object\nscaler = StandardScaler()\ndf_scale = pd.DataFrame(scaler.fit_transform(df_all[num_columns]))\ndf_all = pd.concat([df_ohe.reset_index(drop=True), df_scale.reset_index(drop=True)], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_test = len(DF_test)\ntrain = df_all.iloc[:-len_test]\ntest = df_all.iloc[-len_test:]\nprint(DF_train.shape[0], train.shape[0], DF_test.shape[0], test.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X, y = pd.DataFrame(train).values, Target['polution_clf'].values\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n#X_train.shape[0], X_test.shape[0], y_train.shape[0], y_test.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import PowerTransformer\n\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = DF_train.copy()\nX_test = DF_test.copy()\ny_train = Target['polution_clf']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_, X_val, y_train_, y_val = train_test_split(X_train,y_train,test_size = 0.1, random_state = 34)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model scoring function","metadata":{}},{"cell_type":"code","source":"def calculate_f1_score(model_pipe, X, y):\n    \"\"\"F1 calculation. \n    \n    Parameters:\n    ===========\n    model_pipe: model or pipeline\n    X: features\n    y: real values\n    \"\"\"\n    y_model = model_pipe.predict(X)\n    return f1_score(y, y_model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preparation pipeline","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Numerical data preprocessing (insert missing values and normalization) ","metadata":{}},{"cell_type":"code","source":"numerical_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n   ('scaler', MinMaxScaler())\n])\nnumerical_pipe","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Categorical data preprocessing (insert missing values + OHE)","metadata":{}},{"cell_type":"code","source":"categorical_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent', )),\n    ('encoder', OneHotEncoder(drop='if_binary', handle_unknown='ignore', sparse=False))\n])\ncategorical_pipe","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Concatinate preprocessing pipilines","metadata":{}},{"cell_type":"code","source":"preprocessors = ColumnTransformer(transformers=[\n    ('num', numerical_pipe, num_columns[1:]),\n    ('cat', categorical_pipe, cat_columns)\n])\npreprocessors","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Concatinate preprocessing pipeline and model","metadata":{}},{"cell_type":"code","source":"pipe = Pipeline([\n    ('preprocessors', preprocessors),\n    ('model', LogisticRegression(C=2, random_state=42, max_iter = 100000))\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe.fit(X_train_, y_train_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LogisticRegression","metadata":{}},{"cell_type":"code","source":"print (classification_report(y_test, y_predict, target_names=['polution_clf']))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CatBoost","metadata":{}},{"cell_type":"markdown","source":"## Sumbission results","metadata":{}},{"cell_type":"code","source":"! rm /kaggle/working/water-pollution/Submission.csv\n! mkdir /kaggle/working/water-pollution/","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Submission.to_csv('/kaggle/input/water-pollution/water pollution (data for classification models)/Submission.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir ~/.kaggle\n! touch ~/.kaggle/kaggle.json\n! echo '{\"username\":\"hydramst\",\"key\": \"\" }' > ~/.kaggle/kaggle.json\n! chmod 600 ~/.kaggle/kaggle.json","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat ~/.kaggle/kaggle.json","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#! kaggle competitions submit -c sf-matml-2022-classification -f Submission.csv -m \"Message\"","metadata":{},"execution_count":null,"outputs":[]}]}